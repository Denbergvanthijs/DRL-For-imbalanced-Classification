{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from get_data import load_data\n",
    "from utils import calculate_metrics, load_model, make_predictions\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "MODELS_DIR = \"./models\"\n",
    "imb_rate = 0.01  # Imbalance rate\n",
    "min_class = [1]  # Minority classes, must be same as trained model\n",
    "maj_class = [0]  # Majority classes, must be same as trained model\n",
    "datasource = \"credit\"  # The dataset to be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Imbalance ratio `p`:\n\tdataset:    n=492, p=0.001730\n\ttrain:      n=295, p=0.001729\n\ttest:       n=98, p=0.001723\n\tvalidation: n=99, p=0.001741\n"
    }
   ],
   "source": [
    "# Remove classes ∉ {min_class, maj_class}, imbalance the dataset\n",
    "# Make sure the same seed is used as during training to ensure no data contamination\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = load_data(datasource, imb_rate, min_class, maj_class)  # Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 31/31 [01:34<00:00,  3.06s/it]\n"
    }
   ],
   "source": [
    "all_stats = {\"Gmean\": [], \"Fdot5\": [], \"F1\": [], \"F2\": [], \"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []}\n",
    "\n",
    "for fp_model in tqdm(os.listdir(MODELS_DIR)):\n",
    "    model = load_model(f\"{MODELS_DIR}/{fp_model}\")\n",
    "    y_pred = make_predictions(model, X_test)\n",
    "    stats = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    for k, v in stats.items():\n",
    "        all_stats[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Gmean: 0.497058 Fdot5: 0.011255 F1: 0.017559 F2: 0.040030 TP: 71.516129 TN: 31701.774194 FP: 25162.225806 FN: 26.483871 "
    }
   ],
   "source": [
    "for k in all_stats.keys():\n",
    "    print(f\"{k}: {np.mean(all_stats[k]):.6f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Best scoring model is: 20200928_FN16_FP35.h5 with F1 score of 0.045603'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "maxF1 = max(all_stats.get(\"F1\"))\n",
    "maxF1_index = all_stats.get(\"F1\").index(maxF1)\n",
    "f\"Best scoring model is: {os.listdir(MODELS_DIR)[maxF1_index]} with F1 score of {maxF1:.6f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}