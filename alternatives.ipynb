{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from get_data import load_data\n",
    "from utils import calculate_metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "imb_rate = 0.01  # Imbalance rate\n",
    "min_class = [1]  # Minority classes\n",
    "maj_class = [0]  # Majority classes\n",
    "datasource = \"credit\"  # The dataset to be selected\n",
    "columns = [\"gmean\", \"fmeasure\", \"MCC\", \"MAE\", \"precision\", \"recall\", \"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "scale = 578  # scale = (y_train.shape[0] - y_train.sum()) // y_train.sum()  # Proportion of majority to minority rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_experiment(model, modelname: str, n_repetition: int=100, log_every: int=10):\n",
    "    \"\"\"Repeats the process of splitting data, training model and generating stats several times.\"\"\"\n",
    "    with open(f\"./logs_alt/{modelname}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\", 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i in range(n_repetition):\n",
    "            X_train, y_train, X_test, y_test, X_val, y_val = load_data(datasource, imb_rate, min_class, maj_class, print_stats=False)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            stats = calculate_metrics(y_test, y_pred)  # Get stats as dictionairy\n",
    "            writer.writerow(stats)  # Write dictionairy as row\n",
    "\n",
    "            if not i % log_every:\n",
    "                print(f\"{i}: FN: {stats.get('FN')}, FP: {stats.get('FP')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: FN: 17, FP: 11\n",
      "10: FN: 17, FP: 8\n",
      "20: FN: 14, FP: 8\n",
      "30: FN: 16, FP: 12\n",
      "40: FN: 15, FP: 11\n",
      "50: FN: 17, FP: 11\n",
      "60: FN: 17, FP: 6\n",
      "70: FN: 16, FP: 8\n",
      "80: FN: 17, FP: 7\n",
      "90: FN: 15, FP: 7\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective=\"binary:logitraw\", scale_pos_weight=scale, eval_metric=\"aucpr\", max_delta_step=1)\n",
    "repeat_experiment(model, \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: FN: 14, FP: 53\n",
      "10: FN: 12, FP: 58\n",
      "20: FN: 14, FP: 55\n",
      "30: FN: 14, FP: 57\n",
      "40: FN: 13, FP: 50\n",
      "50: FN: 14, FP: 55\n",
      "60: FN: 12, FP: 59\n",
      "70: FN: 14, FP: 52\n",
      "80: FN: 15, FP: 57\n",
      "90: FN: 13, FP: 53\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.01, max_iter=1_000, class_weight={1: scale // 24})\n",
    "repeat_experiment(model, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: FN: 15, FP: 48\n",
      "10: FN: 12, FP: 6511\n",
      "20: FN: 18, FP: 44\n",
      "30: FN: 21, FP: 31\n",
      "40: FN: 19, FP: 50\n",
      "50: FN: 25, FP: 39\n",
      "60: FN: 20, FP: 49\n",
      "70: FN: 21, FP: 39\n",
      "80: FN: 18, FP: 39\n",
      "90: FN: 18, FP: 43\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss=\"log\", alpha=0.001, max_iter=10_000, early_stopping=True, class_weight={1: scale // 24})\n",
    "repeat_experiment(model, \"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.19 16.39 0.865271\n",
      "56.21 13.74 0.718327\n",
      "793.13 19.89 0.699466\n"
     ]
    }
   ],
   "source": [
    "fn_xgb = \"./logs_alt/XGB_20200923_142438.csv\"\n",
    "fn_lr = \"./logs_alt/LR_20200923_144822.csv\"\n",
    "fn_sgd = \"./logs_alt/SGD_20200923_150542.csv\"\n",
    "\n",
    "for fn in (fn_xgb, fn_lr, fn_sgd):\n",
    "    df = pd.read_csv(fn, sep=',')\n",
    "    print(df.FP.mean(), df.FN.mean(), df.fmeasure.mean().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
